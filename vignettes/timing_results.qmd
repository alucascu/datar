---
title: Timing Results
format: 
  html:
    toc: true
    html-math-method: mathjax

vignette: >
  %\VignetteIndexEntry{Timing Results}
  %\VignetteEngine{quarto::html}
  %\VignetteEncoding{UTF-8}
---

# Timing of Different Functions
This package includes several functions aimed at the estimation of two main parameters. The first, HLE1, computes the Hodges-Lehmann
estimator of location. While the second, HLE2, computes the Hodges-Lehmann estimator of shift. There are 2 implementations of each
of these functions, one based on the base-R function: `outer` and another based in a C++ file (namely using the function `nth_element()`).
Conventional wisdom would assume that the faster of these two implementations would be those based in C++. To put this to the test, 
we will run timings using multiple distribution with multiple sample sizes. 

```{r}
#| echo: true
library(datar)
startThat("tidyverse")

# Functions to make this easier
hle1_timing <- function(size_vec, rng_engine, num_it = 30){
  result <- data.frame()
  for(i in size_vec){
    for(j in seq_len(num_it)){
      x <- rng_engine(i, 5)
      outer_res <- as.data.frame(t(as.data.frame(system.time(outer_hle1(x))))) %>%
        select(1:3) %>% 
        cbind(data.frame(method = "outer", size = i))
      cpp_res <- as.data.frame(t(as.data.frame(system.time(cpp_hle1(x))))) %>% 
        select(1:3) %>% 
        cbind(data.frame(method = "C++", size = i))
      results <- rbind(outer_res, cpp_res)
      result <- rbind(result, results)
    }
  }
  return(result)
}

hle2_timing <- function(size_vec, rng_engine, num_it = 30){
  result <- data.frame()
  for(i in size_vec){
    for(j in seq_len(num_it)){
      x <- rng_engine(i, 5)
      y <- rng_engine(i, 10)
      outer_res <- as.data.frame(t(as.data.frame(system.time(outer_hle2(x, y))))) %>%
        select(1:3) %>% 
        cbind(data.frame(method = "outer", size = i))
      cpp_res <- as.data.frame(t(as.data.frame(system.time(cpp_hle2(x, y))))) %>% 
        select(1:3) %>% 
        cbind((data.frame(method = "C++", size = i)))
      results <- rbind(outer_res, cpp_res)
      result <- rbind(result, results)
    }
  }
  return(result)
}
```
# Timing
With the initial setup out of the way, we can actually run the timings. The two distributions I will be using are the Normal (`rnorm`) and
the exponential (`rexp`). On top of this, I will do 30 iterations of vector sizes from 10 to 10000.
```{r}
size_vec <- seq(10, 40000, length.out = 14) 

```

## Exponential Distribution
```{r}
HLE1 <- hle1_timing(size_vec, rexp, num_it = 10)
HLE2 <- hle2_timing(size_vec, rexp, num_it = 10)
```

```{r}
#| label: background
#| output: false
#| echo: false

HLE11 <- HLE1 %>% group_by(method, size) %>% summarize(user.self = mean(user.self))
HLE22 <- HLE2 %>% group_by(method, size) %>% summarize(user.self = mean(user.self))

```
```{r}
#| label: HLE1-Plot
#| fig-caption: "Results from timing simulation on HLE1 for both implementations using an exponential distribution" 
#| echo: false
ggplot(data = HLE1, mapping = aes(x = size, y = user.self, color = method)) +
  geom_point() + 
  geom_point(data = HLE11, mapping = aes(x = size, y = user.self, color = method), size = 4) +
  labs(title = "HLE1 Timing Results") + 
  xlab("Number of Elements in Simulation") + 
  ylab("User-Requested CPU Time [s]")
```


```{r}
#| label: HLE2-Plot
#| fig-caption: "Results from timing simulation on HLE2 for both implementiations using an exponential distribution." 
#| echo: false
ggplot(data = HLE2, mapping = aes(x = size, y = user.self, color = method)) +
  geom_point() + 
  geom_point(data = HLE22, mapping = aes(x = size, y = user.self, color = method), size = 4) +
  labs(title = "HLE2 Timing Results") + 
  xlab("Number of Elements in Simulation") + 
  ylab("User-Requested CPU Time [s]")

```


## Normal Distribution
```{r}
HLE1 <- hle1_timing(size_vec, rnorm, num_it = 10)
HLE2 <- hle2_timing(size_vec, rnorm, num_it = 10)
```

```{r}
#| label: background-norm
#| output:  false
#| echo: false

HLE11 <- HLE1 %>% group_by(method, size) %>% summarize(user.self = mean(user.self))
HLE22 <- HLE2 %>% group_by(method, size) %>% summarize(user.self = mean(user.self))

```
```{r}
#| label: HLE1-Plot-Norm
#| fig-caption: "Results from timing simulation on HLE1 for both implementations using a normal distribution" 
#| echo: false
ggplot(data = HLE1, mapping = aes(x = size, y = user.self, color = method)) +
  geom_point() + 
  geom_point(data = HLE11, mapping = aes(x = size, y = user.self, color = method), size = 4) +
  labs(title = "HLE1 Timing Results") + 
  xlab("Number of Elements in Simulation") + 
  ylab("User-Requested CPU Time [s]")
```


```{r}
#| label: HLE2-Plot-Norm
#| fig-caption: "Results from timing simulation on HLE2 for both implementiations using a normal distribution." 
#| echo: false
ggplot(data = HLE2, mapping = aes(x = size, y = user.self, color = method)) +
  geom_point() + 
  geom_point(data = HLE22, mapping = aes(x = size, y = user.self, color = method), size = 4) +
  labs(title = "HLE2 Timing Results") + 
  xlab("Number of Elements in Simulation") + 
  ylab("User-Requested CPU Time [s]")
```

What we see here is that the functions `cpp_hle1` and  `cpp_hle2` are, on average, much faster than their `outer` counterparts. 


